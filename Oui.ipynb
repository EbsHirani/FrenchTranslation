{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oui.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NvhjQdg-vmIyi0IkSu8kBuEzOP6mZ1M1",
      "authorship_tag": "ABX9TyNRV5WTQWGw6N4pmmPLzDls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EbsHirani/FrenchTranslation/blob/master/Oui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAmkgs0iiwrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "eng = []\n",
        "fre = []\n",
        "with open(\"small_vocab_en.csv\", \"r\") as csvfile:\n",
        "  csvreader = csv.reader(csvfile)\n",
        "  for row in csvreader:\n",
        "    new = \"\" \n",
        "    for i in row:\n",
        "      new = new + i\n",
        "    eng.append(new)\n",
        "with open(\"small_vocab_fr.csv\", \"r\") as csvfile:\n",
        "  csvreader = csv.reader(csvfile)\n",
        "  for row in csvreader:\n",
        "    new = \"\" \n",
        "    for i in row:\n",
        "      new = new + i\n",
        "    fre.append(new)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqqv4OfmFvAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbCzGXg_Gnyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng = pd.Series(eng)\n",
        "fre = pd.Series(fre)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeuFWau4oFJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "dc15f888-4686-4224-ef08-a5bce9fee97d"
      },
      "source": [
        "eng.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    new jersey is sometimes quiet during autumn  a...\n",
              "1    the united states is usually chilly during jul...\n",
              "2    california is usually quiet during march  and ...\n",
              "3    the united states is sometimes mild during jun...\n",
              "4    your least liked fruit is the grape  but my le...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feitAH2WoH5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "5336992b-a252-4d6c-8c68-e6913b667235"
      },
      "source": [
        "fre.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    new jersey est parfois calme pendant l' automn...\n",
              "1    les états-unis est généralement froid en juill...\n",
              "2    california est généralement calme en mars  et ...\n",
              "3    les états-unis est parfois légère en juin  et ...\n",
              "4    votre moins aimé fruit est le raisin  mais mon...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK4z7qOfJOf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6c9cfe5-cdbb-4997-a34d-510224e99899"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "fre = fre.apply(lambda x:  x.lower()+ \" <EOS>\")\n",
        "fre_input = fre.copy().apply(lambda x : \"<BOS> \" + x )\n",
        "eng = eng.apply(lambda x: x.lower())\n",
        "\n",
        "def tokenize(data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  return tokenizer.texts_to_sequences(data), tokenizer\n",
        "def pad_seq(sequences):\n",
        "  padded = pad_sequences(sequences, padding = \"post\")\n",
        "  return padded"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLBGsjyOO51a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_seq, eng_tok = tokenize(eng.values)\n",
        "fre_input_seq, fre_tok = tokenize(fre_input.values)\n",
        "fre_output_seq = fre_tok.texts_to_sequences(fre.values)\n",
        "eng_seq = pad_seq(eng_seq)\n",
        "# fre_output_seq = pad_seq(fre_output_seq)\n",
        "fre_input_seq = pad_seq(fre_input_seq)\n",
        "#fre_output_seq = fre_output_seq.reshape(fre_output_seq.shape[0], fre_output_seq.shape[1], 1) #for sparse categorical crsooentropy\n",
        "eng_max = eng_seq.shape[1]\n",
        "fre_max = fre_input_seq.shape[1]\n",
        "fre_output_seq = pad_sequences(fre_output_seq, padding = \"post\", maxlen = fre_max)\n",
        "eng_vocab_len = len(eng_tok.word_index)\n",
        "fre_vocab_len = len(fre_tok.word_index)\n",
        "fre_idx = {ids: word for word, ids in fre_tok.word_index.items()}\n",
        "fre_wordx = {word: ids for word, ids in fre_tok.word_index.items()}\n",
        "fre_idx[0] = '<PAD>' \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZicqVxziNPZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "fre_output_seq = to_categorical(fre_output_seq, num_classes = fre_vocab_len+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf07TMy-f6WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09c8ba3d-6b6d-4793-cb7a-a6944a9adc94"
      },
      "source": [
        "eng_seq.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137860, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v67Of97mZTjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Lambda, Flatten, LSTM, Input, Embedding\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import  backend as K\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization , MaxPooling2D, Activation\n",
        "LR = 1e-2\n",
        "enc_input = Input(shape = (None,))\n",
        "enc_emb = Embedding(eng_vocab_len+1, 64)(enc_input)\n",
        "enc_lstm =  LSTM(64, return_state = True)\n",
        "_ , state_h, state_c = enc_lstm(enc_emb)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_emb = Embedding(fre_vocab_len +1, 64)\n",
        "dec_emb_out = dec_emb(dec_inputs)\n",
        "dec_lstm = LSTM(64, return_sequences = True, return_state = True)\n",
        "dec_out, _, _ = dec_lstm(dec_emb_out, initial_state = enc_states)\n",
        "dec_soft = Dense(fre_vocab_len+1, activation = \"softmax\")\n",
        "dec_out = dec_soft(dec_out)\n",
        "model = Model([enc_input, dec_inputs], dec_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqxu6ZcftCWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "model.compile(optimizer = Adam(LR), loss = categorical_crossentropy, metrics = [\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FQFAr83SWtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXgDUFn3uuMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "25236b80-997a-485a-f1da-93d4f6b41bf4"
      },
      "source": [
        "model.fit([eng_seq, fre_input_seq], fre_output_seq, batch_size = 128, epochs = 100,validation_split = 0.05, callbacks =[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7), ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 130967 samples, validate on 6893 samples\n",
            "Epoch 1/100\n",
            "130967/130967 [==============================] - 119s 910us/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0258 - val_accuracy: 0.9918\n",
            "Epoch 2/100\n",
            "130967/130967 [==============================] - 118s 904us/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.0313 - val_accuracy: 0.9896\n",
            "Epoch 3/100\n",
            "130967/130967 [==============================] - 118s 903us/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0556 - val_accuracy: 0.9837\n",
            "Epoch 4/100\n",
            "130967/130967 [==============================] - 114s 874us/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0405 - val_accuracy: 0.9879\n",
            "Epoch 5/100\n",
            "130967/130967 [==============================] - 119s 912us/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0245 - val_accuracy: 0.9919\n",
            "Epoch 6/100\n",
            "130967/130967 [==============================] - 120s 913us/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0275 - val_accuracy: 0.9910\n",
            "Epoch 7/100\n",
            "130967/130967 [==============================] - 124s 948us/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0301 - val_accuracy: 0.9900\n",
            "Epoch 8/100\n",
            "130967/130967 [==============================] - 121s 925us/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.0237 - val_accuracy: 0.9921\n",
            "Epoch 9/100\n",
            "130967/130967 [==============================] - 123s 941us/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0278 - val_accuracy: 0.9914\n",
            "Epoch 10/100\n",
            "130967/130967 [==============================] - 125s 953us/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0258 - val_accuracy: 0.9917\n",
            "Epoch 11/100\n",
            "130967/130967 [==============================] - 126s 963us/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0251 - val_accuracy: 0.9920\n",
            "Epoch 12/100\n",
            "130967/130967 [==============================] - 126s 964us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
            "Epoch 13/100\n",
            "130967/130967 [==============================] - 125s 958us/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0326 - val_accuracy: 0.9899\n",
            "Epoch 14/100\n",
            "130967/130967 [==============================] - 126s 960us/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0428 - val_accuracy: 0.9861\n",
            "Epoch 15/100\n",
            "130967/130967 [==============================] - 123s 943us/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.0282 - val_accuracy: 0.9910\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc867b1db38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl9u9Njt1FhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_model = Model(enc_input, enc_states)\n",
        "state_h_in = Input(shape = (64,))\n",
        "state_c_in  = Input(shape = (64,))\n",
        "dec_state_in = [state_h_in,state_c_in]\n",
        "dec_emb_out_pred = dec_emb(dec_inputs) \n",
        "dec_out_pred, state_h_out, state_c_out = dec_lstm(dec_emb_out_pred, initial_state = dec_state_in)\n",
        "dec_out_pred = dec_soft(dec_out_pred)\n",
        "dec_model = Model([dec_inputs] + dec_state_in, [dec_out_pred, state_h_out, state_c_out])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsSLQcUPRFRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_french(seq):\n",
        "  eng_pred = pad_sequences(eng_tok.texts_to_sequences([seq]), maxlen = eng_max, padding = \"post\")\n",
        "  dec_init = enc_model.predict(eng_pred)\n",
        "  dec_word = np.array([[fre_wordx[\"bos\"]]]) #<BOS> and <EOS> are getting tokenized to bos and eos by keras tokenizer, better practice would\n",
        "                                            #better practice would be to append <BOS> and <EOS> to the numpy array after tokenization\n",
        "  stop = False\n",
        "  fre_sentence = \"\"\n",
        "  while not stop:\n",
        "      output = dec_model.predict([dec_word] + dec_init)\n",
        "      output_seq = output[0]\n",
        "      new_states = output[1:]\n",
        "      new_id = np.argmax(output_seq[0,-1,:])\n",
        "      new_word = fre_idx[new_id]\n",
        "      \n",
        "\n",
        "      if (new_word ==  \"eos\" or len(fre_sentence.split()) == fre_max):\n",
        "        stop = True\n",
        "      else: \n",
        "        fre_sentence += new_word + \" \"\n",
        "      dec_word = np.array([[new_id]]) \n",
        "      dec_init = new_states\n",
        "  return fre_sentence\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_hl2MZq07ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99dd5bfc-d685-45da-a8b7-b0fc95d8903d"
      },
      "source": [
        "predict_french(\"how is the weather\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comment était le temps dans en octobre dernier '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8If4H4_JH3R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_model_json = enc_model.to_json()\n",
        "with open(\"enc_model.json\", \"w\") as json_file:\n",
        "    json_file.write(encoding_model_json)\n",
        "decoding_model_json = dec_model.to_json()\n",
        "with open(\"enc_model.json\", \"w\") as json_file:\n",
        "    json_file.write(decoding_model_json)\n",
        "enc_model.save_weights(\"enc_model.h5\")\n",
        "dec_model.save_weights(\"dec_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}