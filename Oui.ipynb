{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oui.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPU+l2Lb1RB4dDVuDqnbsxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EbsHirani/FrenchTranslation/blob/master/Oui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYqE9QPBA_CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/oui\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqqv4OfmFvAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK4z7qOfJOf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "fre_input = fre.apply(lambda x: \"<BOS> \" + x.lower()+ \" <EOS>\")\n",
        "fre = fre.apply(lambda x: x.lower() + \" <EOS>\")\n",
        "eng = eng.apply(lambda x: x.lower())\n",
        "\n",
        "def tokenize(data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  return tokenizer.texts_to_sequences(data), tokenizer\n",
        "def pad_seq(sequences):\n",
        "  padded = pad_sequences(sequences, padding = \"post\")\n",
        "  return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLBGsjyOO51a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_seq, eng_tok = tokenize(eng)\n",
        "fre_input_seq, fre_tok = tokenize(fre_input)\n",
        "fre_output_seq = fre_tok.texts_to_sequences(fre)\n",
        "eng_seq = pad_seq(eng_seq)\n",
        "fre_output_seq = pad_seq(fre_output_seq)\n",
        "fre_input_seq = pad_seq(fre_input_seq)\n",
        "fre_output_seq = fre_output_seq.reshape(fre_output_seq.shape[0], fre_output_seq.shape[1], 1) #for sparse categorical crsooentropy\n",
        "eng_max = eng_seq.shape[1]\n",
        "fre_max = fre_input_seq.shape[1]\n",
        "eng_vocab_len = len(eng_tok.word_indices)\n",
        "fre_vocab_len = len(fre_tok.word_indices)\n",
        "fre_idx = {ids: word for word, ids in fre_tok.word_index.items()}\n",
        "fre_wordx = {word: ids for word, ids in fre_tok.word_index.items()}\n",
        "index_to_words[0] = '<PAD>' \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v67Of97mZTjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Lambda, Flatten, LSTM, CuDNNLSTM\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import  backend as K\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.layers import BatchNormalization , MaxPooling2D, Activation\n",
        "LR = 1e-3\n",
        "enc_input = Input(shape = (None,))\n",
        "enc_emb = Embedding(eng_vocab_len, 64)(enc_input)\n",
        "enc_lstm =  CuDNNLSTM(50, return_state = True)\n",
        "_ , state_h, state_c = enc_lstm(emb)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_emb = Embedding(fre_vocab_len, 64)\n",
        "dec_emb_out = dec_emb(dec_input)\n",
        "dec_lstm = CuSNNLSTM(50, return_sequences = True, return_state = True)\n",
        "dec_out, _, _ = dec_lstm(dec_emb_out, initial_state = enc_states)\n",
        "dec_soft = Dense(fre_vocab_len, activation = \"softmax\")\n",
        "dec_pred = dec_soft(dec_out)\n",
        "\n",
        "model = Model([enc_input, dec_input], dec_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqxu6ZcftCWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = Adam(LR), loss = sparse_categorical_crossentropy, metrics = [\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXgDUFn3uuMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([eng_seq, fre_input_seq], fre_output, batch_size = 128, epochs = 100, callbacks =[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50), ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl9u9Njt1FhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_model = Model(enc_input, enc_states)\n",
        "dec_state_in = [Input(shape = (50,)),Input(shape = (50,))]\n",
        "dec_emb_out_pred = dec_emb(dec_inputs) \n",
        "dec_out_pred, state_h_out, state_c_out = dec_lstm(dec_emb_out_pred, initial_state = dec_state_in)\n",
        "dec_out_pred = dec_soft(dec_out_pred)\n",
        "dec_model = Model([dec_inputs, dec_state_in], [dec_out_pred, [state_h_out, state_c_out]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsSLQcUPRFRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_french(seq):\n",
        "  dec_init = enc_model.predict(seq)\n",
        "  dec_word = np.array([[fre_wordx[\"<BOS>\"]]])\n",
        "  stop = False\n",
        "  fre_sentence = \"\"\n",
        "  while not stop:\n",
        "      output = dec_model.predict([dec_seq, dec_init])\n",
        "      output_seq = output[0]\n",
        "      new_states = output[1]\n",
        "      new_id = np.argmax(ouput_seq[0,-1,:])\n",
        "      new_word = fre_id[new_id]\n",
        "      fre_sentence += new_word + \" \"\n",
        "\n",
        "      if (new_word = \"<EOS>\" or len(fre_sentence.split()) == fre_max):\n",
        "        stop = True\n",
        "      dec_word = np.array([[new_id]]) \n",
        "      dec_init = new_states\n",
        "  return fre_sentence\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}